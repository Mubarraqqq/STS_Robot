<div align="center">
    <h1> ğŸ—£ï¸ Speech-to-Speech Retrieval-Augmented Assistant (Bruce)</h1>
    <img src="S2S_IMG.png" width='650' /> 
</div>

<br>
<br>

**Bruce** is an intelligent voice assistant pipeline that listens, understands, retrieves, reasons, and speaks â€” enabling seamless speech-to-speech interaction powered by Retrieval-Augmented Generation (RAG), whisper-based transcription, and wake-word activation via Porcupine.

---

## ğŸš€ Features

- ğŸ™ï¸ **Wake Word Detection**: Trigger interaction with the phrase â€œHey Bruceâ€ using [Picovoice Porcupine](https://github.com/Picovoice/porcupine).
- ğŸ§  **RAG-based Reasoning**: Context-aware generation using an embedded vector database (`faiss_index.idx`) with chunked document retrieval.
- ğŸ—£ï¸ **Speech-to-Text + Text-to-Speech**: Uses Whisper for transcription and `pyttsx3` (or compatible engine) for natural voice synthesis.
- âš¡ **Real-time Interaction**: Listens for user input, queries a document corpus, and returns spoken responses in a human-like loop.

---

## ğŸ§± Project Structure

```S2S RAG/
â”œâ”€â”€ S2S_v8.py / S2S_v9.py # Main assistant logic
â”œâ”€â”€ .env # Environment variables (API keys, config)
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ doc_chunks.pkl # Pickled document chunks for retrieval
â”œâ”€â”€ embeddings.npy # Pre-computed document embeddings
â”œâ”€â”€ faiss_index.idx # FAISS index for fast similarity search
â”œâ”€â”€ Hey-Bruce_en_windows_v3_0_0.ppn # Porcupine wake word model
â”œâ”€â”€ info.txt # Text Corpus of which the RAG system wpuld make retrieval from 

```
---



## ğŸ› ï¸ Setup Instructions

### 1. Set up Python environment

```bash
pip install -r requirements.txt
```

### 2. Add `.env` file

Create a `.env` file and add required environment variables:

```env
TOGETHER_API_KEY=your_api_key
PORCUPINE_API_KEY = your_api_key
GROQ_API_KEY = your_api_key
OPEN_API = your_api_key

```

### 3. Run the assistant

```bash
python S2S_v9.py
```

---

## ğŸ§  How It Works

### ğŸ”Š Wake Word Detection
Listens for the wake word **â€œHey Bruceâ€** using a `.ppn` model via Porcupine. 

### ğŸ—£ï¸ Speech-to-Text (STT)
Captures and transcribes user speech using OpenAIâ€™s Whisper.

### ğŸ” Contextual Retrieval
Searches document embeddings using FAISS to find the most relevant context from `doc_chunks.pkl`.

### ğŸ§  Language Generation
Sends query + context to a powerful language model (e.g., TogetherAI LLaMA) and retrieves the response.

### ğŸ” Text-to-Speech (TTS)
Converts the generated response back to voice using `pyttsx3`.

---

## ğŸ“¦ Dependencies

Key libraries (see `requirements.txt`):

- `openai-whisper`
- `pyttsx3`
- `faiss-cpu`
- `python-dotenv`
- `numpy`
- `pickle`
- `sounddevice`
- `pvporcupine` *(Porcupine wake word detection)*

---

## ğŸ§ª Example Use Case

> **You**: "Hey Bruce, what is retrieval-augmented generation?"  
> **Assistant**: (searches documents)  
> **Response**: "Retrieval-Augmented Generation (RAG) is a method that improves language models by providing external context from a document database..."

---

## ğŸ“ Roadmap

- [ ] Add multilingual support  
- [ ] Improve response latency via local quantized models  
- [ ] Add GUI interface  
- [ ] Deploy as web API for Raspberry Pi/Edge use  

---

## ğŸ” Disclaimer

- Ensure you setup your personalized porcupine model (.ppn file) for the catch phrase 'Hey Bruce'
- Also make sure you have an 'info.txt' file which would serve as the text corpus knowledge base for the RAG system.   
---

## ğŸ¤ Acknowledgements

- [Porcupine by Picovoice](https://github.com/Picovoice/porcupine)  
- [Whisper by OpenAI](https://github.com/openai/whisper)  
- [FAISS by Meta AI](https://github.com/facebookresearch/faiss)  
- [Together AI](https://www.together.ai/)  

---

## ğŸ“œ License

This project is licensed under the **MIT License**. See `LICENSE` for more information.
